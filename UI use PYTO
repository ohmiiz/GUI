import pyto_ui as ui
import cv2
import sys
import math
from math import *
import numpy as np
import cv2.aruco as aruco


def button_pressed(sender):
    sender.superview.close()


def hello(sender):
    print("hello")


def camera(sender):
    casc_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
    face_cascade = cv2.CascadeClassifier(casc_path)

    device = 1  # Front camera
    try:
        device = int(sys.argv[1])  # 0 for back camera
    except IndexError:
        pass

    cap = cv2.VideoCapture(device)

    while cap.isOpened():

        # Capture frame-by-frame
        ret, frame = cap.read()

        # Check if frame is not empty
        if not ret:
            continue

        # Auto rotate camera
        frame = cv2.autorotate(frame, device)

        # Convert from BGR to RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        faces = face_cascade.detectMultiScale(
            frame,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30, 30),
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        # Draw a rectangle around the faces
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Display the resulting frame
        cv2.imshow('frame', frame)

def aruco(sender):
    
    cap = cv2.VideoCapture(0)  # Get the camera source
    matrix_coefficients = [[1.25019753e+03, 0.00000000e+00, 8.31027626e+02, ],  # From calibrte camera
                           [0.00000000e+00, 1.24629197e+03, 4.93761478e+02, ],
                           [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]
    distortion_coefficients = [[0.22126322, -0.38411381, -0.01361529, 0.03204828, -0.06211731]]  # From calibrte camera
    data_tvecs = []  # Prepare to add tvec 
    value_dis = []  # Prepare to get result distance(scalar) unit meter

    def track(matrix_coefficients, distortion_coefficients):
        while True:
            ret, frame = cap.read()
            if not ret:
                continue
            # operations on the frame come here
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Change grayscale
            aruco_dict = aruco.Dictionary_get(aruco.DICT_5X5_250)  # Use 5x5 dictionary to find markers
            parameters = aruco.DetectorParameters_create()  # Marker detection parameters
            # lists of ids and the corners beloning to each id
            corners, ids, rejected_img_points = aruco.detectMarkers(gray, aruco_dict,
                                                                    parameters=parameters,
                                                                    cameraMatrix=np.float32(matrix_coefficients),
                                                                    distCoeff=np.float32(distortion_coefficients))

            if np.all(ids is not None):  # If there are markers found by detector
                for i in range(0, len(ids)):  # Iterate in markers
                    # Estimate pose of each marker and return the values rvec and tvec---different from camera coefficients
                    rvec, tvec, markerPoints = aruco.estimatePoseSingleMarkers(corners[i], 0.02,
                                                                               np.float32(matrix_coefficients),
                                                                               np.float32(distortion_coefficients))

                    (rvec - tvec).any()  # get rid of that nasty numpy value array error
                    aruco.drawDetectedMarkers(frame, corners)  # Draw A square around the markers
                    aruco.drawAxis(frame, np.float32(matrix_coefficients), np.float32(distortion_coefficients),
                                   np.float32(rvec), np.float32(tvec), 0.01)  # Draw Axis

                    data_tvecs.append(tvec)  # get every data of tvec in array data_tvecs
                    length = len(data_tvecs)  # For easy to calculate equation
                    if length > 1:
                        diff = data_tvecs[length - 2] - data_tvecs[length - 1]  # Find distance between tvec(vector)
                        sum_tvec = sqrt(np.sum(diff ** 2))  # convert vector to scalar
                        value_dis.append(np.round(sum_tvec, 6))  # get the distance data(scalar)  in array value

            # Display the resulting frame
            cv2.imshow('frame', frame)
            # Wait 3 milisecoonds for an interaction. Check the key and do the corresponding job.
            key = cv2.waitKey(3) & 0xFF
            if key == ord('q'):  # Quit
                print('Distance', value_dis)  # show distance between tvec
                break

                # When everything done, release the capture
                cap.release()
                cv2.destroyAllWindows()

    track(matrix_coefficients, distortion_coefficients)


view = ui.View()
view.background_color = ui.COLOR_SYSTEM_BACKGROUND

button = ui.Button(title="Camera")
button.size = (100, 50)
button.center = (view.width / 4.5, view.height / 1.5)
button.flex = [
    ui.FLEXIBLE_TOP_MARGIN,
    ui.FLEXIBLE_BOTTOM_MARGIN,
    ui.FLEXIBLE_LEFT_MARGIN,
    ui.FLEXIBLE_RIGHT_MARGIN
]
button.action = camera
view.add_subview(button)

button1 = ui.Button(title="Quit")
button1.size = (100, 50)
button1.center = (view.width / 1.5, view.height / 1.5)
button1.flex = [
    ui.FLEXIBLE_TOP_MARGIN,
    ui.FLEXIBLE_BOTTOM_MARGIN,
    ui.FLEXIBLE_LEFT_MARGIN,
    ui.FLEXIBLE_RIGHT_MARGIN
]
button1.action = button_pressed
view.add_subview(button1)

button2 = ui.Button(title="Record")
button2.size = (100, 50)
button2.center = (view.width / 2.5, view.height / 1.5)
button2.flex = [
    ui.FLEXIBLE_TOP_MARGIN,
    ui.FLEXIBLE_BOTTOM_MARGIN,
    ui.FLEXIBLE_LEFT_MARGIN,
    ui.FLEXIBLE_RIGHT_MARGIN
]
button1.action = aruco
view.add_subview(button2)

ui.show_view(view, ui.PRESENTATION_MODE_SHEET)
